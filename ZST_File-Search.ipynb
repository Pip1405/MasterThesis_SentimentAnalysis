{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECOMPRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import subprocess\n",
    "\n",
    "def decompress_zst_file(input_file, output_file):\n",
    "    decompress_command = ['zstd', '--long=31', '-dc', input_file]\n",
    "    with open(output_file, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        with subprocess.Popen(decompress_command, stdout=subprocess.PIPE, universal_newlines=True) as process:\n",
    "            for line in process.stdout:\n",
    "                row = line.strip().split('\\t')\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Beispielaufruf der Funktion\n",
    "input_file = r'/Volumes/WD5TB/reddit/comments/RC_2005-12.zst'\n",
    "output_file = r'/Volumes/WD5TB/Raw_Output_Comments.csv'\n",
    "decompress_zst_file(input_file, output_file)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH WITHIN ONE ZST FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dateipfad: /Volumes/WD5TB/reddit/submissions/RS_2021-01.zst\n",
      "Dateigröße: 8698915333\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 62\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zstandard as zstd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_zst_file(file_path, output_file_path, keyword):\n",
    "    print(\"Dateipfad:\", file_path)\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(\"Dateigröße:\", file_size)\n",
    "\n",
    "    # Ergebnisse in eine CSV-Datei umleiten\n",
    "    with open(output_file_path, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "\n",
    "        with open(file_path, 'rb') as compressed_file:\n",
    "            dctx = zstd.ZstdDecompressor(max_window_size=2147483648)  # Max Window Size auf 4 GB erhöht\n",
    "            reader = dctx.stream_reader(compressed_file)\n",
    "            chunk_size = 10 * 1024 * 1024  # Chunk-Größe auf 10 MB festgelegt\n",
    "            current_line = b''\n",
    "\n",
    "            def line_generator():\n",
    "                for chunk in iter(lambda: reader.read(chunk_size), b''):\n",
    "                    nonlocal current_line\n",
    "                    lines = (current_line + chunk).split(b'\\n')\n",
    "                    for line in lines[:-1]:\n",
    "                        yield line\n",
    "                    current_line = lines[-1]\n",
    "                if current_line:\n",
    "                    yield current_line\n",
    "\n",
    "            # Counter hinzugefügt\n",
    "            counter = 0\n",
    "            for line in line_generator():\n",
    "                counter += process_line(line, csv_writer, keyword)\n",
    "            print(\"Anzahl der Zeilen, die das Schlüsselwort enthalten:\", counter)\n",
    "\n",
    "def process_line(line, csv_writer, keyword):\n",
    "    decoded_line = line.decode('utf-8')\n",
    "    decoded_line = json.loads(decoded_line)\n",
    "    # Check if the keyword is in the \"title\" or \"selftext\"\n",
    "    if keyword.lower() in decoded_line.get(\"title\", \"\").lower() or keyword.lower() in decoded_line.get(\"selftext\", \"\").lower():\n",
    "        # Ergebnisse in die CSV-Datei schreiben\n",
    "        csv_writer.writerow([decoded_line[\"created_utc\"], decoded_line[\"title\"], decoded_line.get(\"selftext\", \"\")])\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Beispielaufruf der Funktion\n",
    "zst_file_path = '/Volumes/WD5TB/reddit/submissions/RS_2021-01.zst'\n",
    "output_file_path = '/Volumes/WD5TB/output202101.csv'\n",
    "keyword = \"$MSFT\"\n",
    "extract_zst_file(zst_file_path, output_file_path, keyword)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH WITHIN DIRECTION (ONE CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/WD5TB/reddit/submissions/RS_2021-01.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 913\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-06.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 143\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-04.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 173\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-03.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 760\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-02.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 826\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-09.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 765\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-04.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 752\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-03.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 158\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-12.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 358\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-12.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 749\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-08.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 796\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-08.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 476\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-10.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 352\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-09.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 461\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-12.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 646\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-02.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 350\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-02.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 506\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-10.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 739\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-11.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 274\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-01.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 559\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-08.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 452\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-10.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 439\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-01.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 330\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-05.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 180\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2020-07.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 973\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-05.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 863\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2021-07.zst\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m output_file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Volumes/WD5TB/all_results.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     53\u001b[0m keyword \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m$TSLA\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 55\u001b[0m extract_zst_files(zst_directory, output_file_path, keyword)\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mextract_zst_files\u001b[0;34m(zst_directory, output_file_path, keyword)\u001b[0m\n\u001b[1;32m     16\u001b[0m zst_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(zst_directory, filename)\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(zst_file_path)\n\u001b[0;32m---> 18\u001b[0m extract_zst_file(zst_file_path, csv_writer, keyword)\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mextract_zst_file\u001b[0;34m(file_path, csv_writer, keyword)\u001b[0m\n\u001b[1;32m     37\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_generator():\n\u001b[0;32m---> 39\u001b[0m     counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m process_line(line, csv_writer, keyword)\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAnzahl der Zeilen, die das Schlüsselwort enthalten:\u001b[39m\u001b[39m\"\u001b[39m, counter)\n",
      "Cell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mprocess_line\u001b[0;34m(line, csv_writer, keyword)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_line\u001b[39m(line, csv_writer, keyword):\n\u001b[1;32m     43\u001b[0m     decoded_line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     decoded_line \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(decoded_line)\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m keyword\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m decoded_line\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mlower() \u001b[39mor\u001b[39;00m keyword\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m decoded_line\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mselftext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mlower():\n\u001b[1;32m     46\u001b[0m         csv_writer\u001b[39m.\u001b[39mwriterow([decoded_line[\u001b[39m\"\u001b[39m\u001b[39mcreated_utc\u001b[39m\u001b[39m\"\u001b[39m], decoded_line[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m], decoded_line\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mselftext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zstandard as zstd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_zst_files(zst_directory, output_file_path, keyword):\n",
    "    # CSV-Datei zum Schreiben öffnen\n",
    "    with open(output_file_path, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "\n",
    "        # Durch alle .zst-Dateien im Verzeichnis iterieren\n",
    "        for filename in os.listdir(zst_directory):\n",
    "            if filename.endswith(\".zst\") and not filename.startswith(\".\"):\n",
    "                year = filename.split(\"_\")[1][:4]\n",
    "                if \"2020\" <= year <= \"2022\":\n",
    "                    zst_file_path = os.path.join(zst_directory, filename)\n",
    "                    print(zst_file_path)\n",
    "                    extract_zst_file(zst_file_path, csv_writer, keyword)\n",
    "\n",
    "def extract_zst_file(file_path, csv_writer, keyword):\n",
    "    with open(file_path, 'rb') as compressed_file:\n",
    "        dctx = zstd.ZstdDecompressor(max_window_size=2147483648)\n",
    "        reader = dctx.stream_reader(compressed_file)\n",
    "        chunk_size = 100 * 1024 * 1024\n",
    "        current_line = b''\n",
    "\n",
    "        def line_generator():\n",
    "            for chunk in iter(lambda: reader.read(chunk_size), b''):\n",
    "                nonlocal current_line\n",
    "                lines = (current_line + chunk).split(b'\\n')\n",
    "                for line in lines[:-1]:\n",
    "                    yield line\n",
    "                current_line = lines[-1]\n",
    "            if current_line:\n",
    "                yield current_line\n",
    "\n",
    "        counter = 0\n",
    "        for line in line_generator():\n",
    "            counter += process_line(line, csv_writer, keyword)\n",
    "        print(\"Anzahl der Zeilen, die das Schlüsselwort enthalten:\", counter)\n",
    "\n",
    "def process_line(line, csv_writer, keyword):\n",
    "    decoded_line = line.decode('utf-8')\n",
    "    decoded_line = json.loads(decoded_line)\n",
    "    if keyword.lower() in decoded_line.get(\"title\", \"\").lower() or keyword.lower() in decoded_line.get(\"selftext\", \"\").lower():\n",
    "        csv_writer.writerow([decoded_line[\"created_utc\"], decoded_line[\"title\"], decoded_line.get(\"selftext\", \"\")])\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Beispielaufruf der Funktion für mehrere .zst-Dateien\n",
    "zst_directory = '/Volumes/WD5TB/reddit/submissions/'\n",
    "output_file_path = '/Volumes/WD5TB/all_results.csv'\n",
    "keyword = \"$TSLA\"\n",
    "\n",
    "extract_zst_files(zst_directory, output_file_path, keyword)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH WITHIN DIRECTION (EACH CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/WD5TB/reddit/submissions/RS_2022-12.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 749\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-08.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 476\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-10.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 352\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-02.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 350\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-01.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 559\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-03.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 393\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-07.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 554\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-09.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 241\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-11.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 397\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-06.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 379\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-05.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 307\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-04.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: 543\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zstandard as zstd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keyword):\n",
    "    # Durch alle .zst-Dateien im Verzeichnis iterieren\n",
    "    for filename in os.listdir(zst_directory):\n",
    "        if filename.endswith(\".zst\") and not filename.startswith(\".\"):\n",
    "            year = filename.split(\"_\")[1][:4]\n",
    "            if \"2022\" <= year <= \"2022\":\n",
    "                zst_file_path = os.path.join(zst_directory, filename)\n",
    "                output_file_path = os.path.join(output_directory, filename.replace('.zst', '.csv'))\n",
    "                print(zst_file_path)\n",
    "                extract_zst_file(zst_file_path, output_file_path, keyword)\n",
    "\n",
    "def extract_zst_file(file_path, output_file_path, keyword):\n",
    "    # CSV-Datei zum Schreiben öffnen\n",
    "    with open(output_file_path, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "\n",
    "        with open(file_path, 'rb') as compressed_file:\n",
    "            dctx = zstd.ZstdDecompressor(max_window_size=2147483648)\n",
    "            reader = dctx.stream_reader(compressed_file)\n",
    "            chunk_size = 100 * 1024 * 1024\n",
    "            current_line = b''\n",
    "\n",
    "            def line_generator():\n",
    "                for chunk in iter(lambda: reader.read(chunk_size), b''):\n",
    "                    nonlocal current_line\n",
    "                    lines = (current_line + chunk).split(b'\\n')\n",
    "                    for line in lines[:-1]:\n",
    "                        yield line\n",
    "                    current_line = lines[-1]\n",
    "                if current_line:\n",
    "                    yield current_line\n",
    "\n",
    "            counter = 0\n",
    "            for line in line_generator():\n",
    "                counter += process_line(line, csv_writer, keyword)\n",
    "            print(\"Anzahl der Zeilen, die das Schlüsselwort enthalten:\", counter)\n",
    "\n",
    "def process_line(line, csv_writer, keyword):\n",
    "    decoded_line = line.decode('utf-8')\n",
    "    decoded_line = json.loads(decoded_line)\n",
    "    if keyword.lower() in decoded_line.get(\"title\", \"\").lower() or keyword.lower() in decoded_line.get(\"selftext\", \"\").lower():\n",
    "        csv_writer.writerow([decoded_line[\"created_utc\"], decoded_line[\"title\"], decoded_line.get(\"selftext\", \"\")])\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Beispielaufruf der Funktion für mehrere .zst-Dateien\n",
    "zst_directory = '/Volumes/WD5TB/reddit/submissions/'\n",
    "output_directory = '/Volumes/WD5TB/'\n",
    "keyword = \"$TSLA\"\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keyword)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH WITHIN DIRECTION (EACH CSV) MULTIPLE KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/WD5TB/reddit/submissions/RS_2022-12.zst\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten: {'$JPM': 44, 'JPM.N': 0, 'JPM Aktie': 0, 'JPMorgan Chase Stock': 0, 'JPM Stock': 2, '$BAC': 58, 'BAC.N': 0, 'BAC Aktie': 0, 'Bank of America Stock': 6, 'BAC Stock': 3, '$WFC': 63, 'WFC.N': 1, 'WFC Aktie': 0, 'Wells Fargo Stock': 0, 'WFC Stock': 1, '$MS': 228, 'MS.N': 218, 'MS Aktie': 0, 'Morgan Stanley Stock': 1, 'MS Stock': 92, '$AXP': 21, 'AXP.N': 0, 'AXP Aktie': 0, 'American Express Stock': 0, 'AXP Stock': 1, '$BX': 71, 'BX.N': 2, 'BX Aktie': 0, 'Blackstone Stock': 0, 'BX Stock': 20, '$GS': 109, 'GS.N': 192, 'GS Aktie': 0, 'Goldman Sachs Stock': 0, 'GS Stock': 102, '$BLK': 31, 'BLK.N': 0, 'BLK Aktie': 0, 'BlackRock Stock': 0, 'BLK Stock': 2}\n",
      "/Volumes/WD5TB/reddit/submissions/RS_2022-08.zst\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 79\u001b[0m\n\u001b[1;32m     69\u001b[0m output_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Volumes/WD5TB/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     70\u001b[0m keywords \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m$JPM\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mJPM.N\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mJPM Aktie\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mJPMorgan Chase Stock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mJPM Stock\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     71\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m$BAC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBAC.N\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBAC Aktie\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBank of America Stock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBAC Stock\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     72\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m$WFC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWFC.N\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWFC Aktie\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWells Fargo Stock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWFC Stock\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m$GS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGS.N\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGS Aktie\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGoldman Sachs Stock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGS Stock\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     77\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m$BLK\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBLK.N\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBLK Aktie\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBlackRock Stock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBLK Stock\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m extract_zst_files(zst_directory, output_directory, keywords)\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mextract_zst_files\u001b[0;34m(zst_directory, output_directory, keywords)\u001b[0m\n\u001b[1;32m     13\u001b[0m output_file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_directory, filename\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.zst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(zst_file_path)\n\u001b[0;32m---> 15\u001b[0m extract_zst_file(zst_file_path, output_file_path, keywords)\n",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m, in \u001b[0;36mextract_zst_file\u001b[0;34m(file_path, output_file_path, keywords)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_generator():\n\u001b[1;32m     44\u001b[0m     \u001b[39mfor\u001b[39;00m keyword \u001b[39min\u001b[39;00m keywords:\n\u001b[0;32m---> 45\u001b[0m         counters[keyword] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m process_line(line, keyword, written_titles, batch_data, csv_writer, batch_size)\n\u001b[1;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAnzahl der Zeilen, die das Schlüsselwort enthalten:\u001b[39m\u001b[39m\"\u001b[39m, counters)\n\u001b[1;32m     48\u001b[0m \u001b[39m# Schreiben Sie die restlichen Daten im Zwischenspeicher in die CSV-Datei\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 54\u001b[0m, in \u001b[0;36mprocess_line\u001b[0;34m(line, keyword, written_titles, batch_data, csv_writer, batch_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_line\u001b[39m(line, keyword, written_titles, batch_data, csv_writer, batch_size):\n\u001b[1;32m     53\u001b[0m     decoded_line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     decoded_line \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(decoded_line)\n\u001b[1;32m     55\u001b[0m     title \u001b[39m=\u001b[39m decoded_line\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mlower()\n\u001b[1;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m keyword\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m title \u001b[39mor\u001b[39;00m keyword\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m decoded_line\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mselftext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mlower():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zstandard as zstd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keywords):\n",
    "    # Durch alle .zst-Dateien im Verzeichnis iterieren\n",
    "    for filename in os.listdir(zst_directory):\n",
    "        if filename.endswith(\".zst\") and not filename.startswith(\".\"):\n",
    "            year = filename.split(\"_\")[1][:4]\n",
    "            if \"2022\" <= year <= \"2022\":\n",
    "                zst_file_path = os.path.join(zst_directory, filename)\n",
    "                output_file_path = os.path.join(output_directory, filename.replace('.zst', '.csv'))\n",
    "                print(zst_file_path)\n",
    "                extract_zst_file(zst_file_path, output_file_path, keywords)\n",
    "\n",
    "def extract_zst_file(file_path, output_file_path, keywords):\n",
    "    # CSV-Datei zum Schreiben öffnen\n",
    "    with open(output_file_path, 'w', newline='') as output_file:\n",
    "        csv_writer = csv.writer(output_file)\n",
    "\n",
    "        with open(file_path, 'rb') as compressed_file:\n",
    "            dctx = zstd.ZstdDecompressor(max_window_size=2147483648)\n",
    "            reader = dctx.stream_reader(compressed_file)\n",
    "            chunk_size = 500 * 1024 * 1024  # Erhöhte Chunk-Größe auf 500 MB\n",
    "            current_line = b''\n",
    "\n",
    "            def line_generator():\n",
    "                for chunk in iter(lambda: reader.read(chunk_size), b''):\n",
    "                    nonlocal current_line\n",
    "                    lines = (current_line + chunk).split(b'\\n')\n",
    "                    for line in lines[:-1]:\n",
    "                        yield line\n",
    "                    current_line = lines[-1]\n",
    "                if current_line:\n",
    "                    yield current_line\n",
    "\n",
    "            batch_size = 1000  # Anzahl der Zeilen pro Batch\n",
    "            batch_data = []  # Zwischenspeicher für Zeilen\n",
    "\n",
    "            counters = {keyword: 0 for keyword in keywords}\n",
    "            written_titles = set()  # Liste der bereits geschriebenen Titel\n",
    "            for line in line_generator():\n",
    "                for keyword in keywords:\n",
    "                    counters[keyword] += process_line(line, keyword, written_titles, batch_data, csv_writer, batch_size)\n",
    "            print(\"Anzahl der Zeilen, die das Schlüsselwort enthalten:\", counters)\n",
    "\n",
    "            # Schreiben Sie die restlichen Daten im Zwischenspeicher in die CSV-Datei\n",
    "            if batch_data:\n",
    "                csv_writer.writerows(batch_data)\n",
    "\n",
    "def process_line(line, keyword, written_titles, batch_data, csv_writer, batch_size):\n",
    "    decoded_line = line.decode('utf-8')\n",
    "    decoded_line = json.loads(decoded_line)\n",
    "    title = decoded_line.get(\"title\", \"\").lower()\n",
    "    if keyword.lower() in title or keyword.lower() in decoded_line.get(\"selftext\", \"\").lower():\n",
    "        if title not in written_titles:  # Überprüfung auf Duplikate\n",
    "            batch_data.append([decoded_line[\"created_utc\"], decoded_line[\"title\"], decoded_line.get(\"selftext\", \"\")])\n",
    "            written_titles.add(title)  # Titel zur Liste der bereits geschriebenen Titel hinzufügen\n",
    "\n",
    "            if len(batch_data) >= batch_size:\n",
    "                csv_writer.writerows(batch_data)\n",
    "                batch_data.clear()  # Zwischenspeicher leeren\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Beispielaufruf der Funktion für mehrere .zst-Dateien\n",
    "zst_directory = '/Volumes/WD5TB/reddit/submissions/'\n",
    "output_directory = '/Volumes/WD5TB/'\n",
    "keywords = [\"$JPM\", \"JPM.N\", \"JPM Aktie\", \"JPMorgan Chase Stock\", \"JPM Stock\", \n",
    "            \"$BAC\", \"BAC.N\", \"BAC Aktie\", \"Bank of America Stock\", \"BAC Stock\", \n",
    "            \"$WFC\", \"WFC.N\", \"WFC Aktie\", \"Wells Fargo Stock\", \"WFC Stock\", \n",
    "            \"$MS\", \"MS.N\", \"MS Aktie\", \"Morgan Stanley Stock\", \"MS Stock\", \n",
    "            \"$AXP\", \"AXP.N\", \"AXP Aktie\", \"American Express Stock\", \"AXP Stock\", \n",
    "            \"$BX\", \"BX.N\", \"BX Aktie\", \"Blackstone Stock\", \"BX Stock\",\n",
    "            \"$GS\", \"GS.N\", \"GS Aktie\", \"Goldman Sachs Stock\", \"GS Stock\",\n",
    "            \"$BLK\", \"BLK.N\", \"BLK Aktie\", \"BlackRock Stock\", \"BLK Stock\"]\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keywords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH WITHIN DIRECTION (EACH CSV) MULTIPLE KEYWORDS OPTIMIZED"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINANCIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-12.zst...\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-10.zst...\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-07.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-10.zst: {'$jpm': 0, 'jpm.n': 0, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 0, '$bac': 0, 'bac.n': 0, 'bac aktie': 0, 'bank of america stock': 2, 'bac stock': 2, '$wfc': 0, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 6, 'wfc stock': 3, '$ms': 0, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 0, 'ms stock': 0, '$axp': 0, 'axp.n': 0, 'axp aktie': 0, 'american express stock': 2, 'axp stock': 0, '$bx': 0, 'bx.n': 0, 'bx aktie': 0, 'blackstone stock': 0, 'bx stock': 0, '$gs': 0, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 4, 'gs stock': 1, '$blk': 0, 'blk.n': 0, 'blk aktie': 0, 'blackrock stock': 5, 'blk stock': 0}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-11.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-12.zst: {'$jpm': 0, 'jpm.n': 0, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 2, '$bac': 0, 'bac.n': 0, 'bac aktie': 0, 'bank of america stock': 2, 'bac stock': 2, '$wfc': 0, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 0, 'wfc stock': 1, '$ms': 0, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 0, 'ms stock': 2, '$axp': 0, 'axp.n': 0, 'axp aktie': 0, 'american express stock': 0, 'axp stock': 1, '$bx': 0, 'bx.n': 1, 'bx aktie': 0, 'blackstone stock': 0, 'bx stock': 1, '$gs': 0, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 0, 'gs stock': 1, '$blk': 0, 'blk.n': 0, 'blk aktie': 0, 'blackrock stock': 0, 'blk stock': 1}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-08.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-07.zst: {'$jpm': 0, 'jpm.n': 0, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 4, '$bac': 0, 'bac.n': 0, 'bac aktie': 0, 'bank of america stock': 0, 'bac stock': 5, '$wfc': 0, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 1, 'wfc stock': 7, '$ms': 0, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 0, 'ms stock': 3, '$axp': 0, 'axp.n': 0, 'axp aktie': 0, 'american express stock': 0, 'axp stock': 1, '$bx': 0, 'bx.n': 0, 'bx aktie': 0, 'blackstone stock': 0, 'bx stock': 4, '$gs': 1, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 2, 'gs stock': 6, '$blk': 0, 'blk.n': 3, 'blk aktie': 0, 'blackrock stock': 1, 'blk stock': 0}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-09.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-11.zst: {'$jpm': 0, 'jpm.n': 0, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 2, '$bac': 0, 'bac.n': 0, 'bac aktie': 0, 'bank of america stock': 2, 'bac stock': 2, '$wfc': 0, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 0, 'wfc stock': 0, '$ms': 0, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 0, 'ms stock': 0, '$axp': 0, 'axp.n': 0, 'axp aktie': 0, 'american express stock': 0, 'axp stock': 1, '$bx': 0, 'bx.n': 0, 'bx aktie': 0, 'blackstone stock': 0, 'bx stock': 1, '$gs': 0, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 1, 'gs stock': 1, '$blk': 0, 'blk.n': 0, 'blk aktie': 0, 'blackrock stock': 0, 'blk stock': 1}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-09.zst: {'$jpm': 0, 'jpm.n': 0, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 0, '$bac': 0, 'bac.n': 0, 'bac aktie': 0, 'bank of america stock': 0, 'bac stock': 0, '$wfc': 0, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 1, 'wfc stock': 0, '$ms': 0, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 0, 'ms stock': 0, '$axp': 0, 'axp.n': 0, 'axp aktie': 0, 'american express stock': 0, 'axp stock': 0, '$bx': 0, 'bx.n': 0, 'bx aktie': 0, 'blackstone stock': 0, 'bx stock': 0, '$gs': 1, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 1, 'gs stock': 0, '$blk': 0, 'blk.n': 0, 'blk aktie': 0, 'blackrock stock': 0, 'blk stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-08.zst: {'$jpm': 0, 'jpm.n': 0, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 5, '$bac': 0, 'bac.n': 0, 'bac aktie': 0, 'bank of america stock': 2, 'bac stock': 5, '$wfc': 0, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 1, 'wfc stock': 3, '$ms': 0, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 0, 'ms stock': 5, '$axp': 0, 'axp.n': 1, 'axp aktie': 0, 'american express stock': 0, 'axp stock': 4, '$bx': 1, 'bx.n': 0, 'bx aktie': 0, 'blackstone stock': 1, 'bx stock': 6, '$gs': 0, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 0, 'gs stock': 4, '$blk': 0, 'blk.n': 0, 'blk aktie': 0, 'blackrock stock': 0, 'blk stock': 7}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Code\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker import extract_zst_file\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keywords):\n",
    "    zst_files = [os.path.join(zst_directory, filename) \n",
    "                 for filename in os.listdir(zst_directory) \n",
    "                 if filename.endswith(\".zst\") and not filename.startswith(\".\") \n",
    "                 and \"2022\" <= filename.split(\"_\")[1][:4] <= \"2022\"]\n",
    "\n",
    "    with Pool(processes=3) as pool:\n",
    "        pool.starmap(extract_zst_file, [(file_path, output_directory, keywords) for file_path in zst_files])\n",
    "\n",
    "\n",
    "zst_directory = '/Users/philippsbresny/Documents/RedditData'\n",
    "output_directory = '/Users/philippsbresny/Library/CloudStorage/OneDrive-Persönlich/VSC/Lazarus_Project'\n",
    "keywords = [\"$JPM\", \"JPM.N\", \"JPM Aktie\", \"JPMorgan Chase Stock\", \"JPM Stock\", \n",
    "            \"$BAC\", \"BAC.N\", \"BAC Aktie\", \"Bank of America Stock\", \"BAC Stock\", \n",
    "            \"$WFC\", \"WFC.N\", \"WFC Aktie\", \"Wells Fargo Stock\", \"WFC Stock\", \n",
    "            \"$MS\", \"MS.N\", \"MS Aktie\", \"Morgan Stanley Stock\", \"MS Stock\", \n",
    "            \"$AXP\", \"AXP.N\", \"AXP Aktie\", \"American Express Stock\", \"AXP Stock\", \n",
    "            \"$BX\", \"BX.N\", \"BX Aktie\", \"Blackstone Stock\", \"BX Stock\",\n",
    "            \"$GS\", \"GS.N\", \"GS Aktie\", \"Goldman Sachs Stock\", \"GS Stock\",\n",
    "            \"$BLK\", \"BLK.N\", \"BLK Aktie\", \"BlackRock Stock\", \"BLK Stock\"]\n",
    "\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keywords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TECHNOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-10.zst...Processing /Users/philippsbresny/Documents/RedditData/RS_2022-07.zst...\n",
      "\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-12.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-10.zst: {'$aapl': 0, 'aapl.oq': 0, 'aapl aktie': 1, 'apple stock': 59, 'aapl stock': 5, '$msft': 0, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 28, 'msft stock': 5, '$googl': 0, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 15, 'googl stock': 0, '$nvda': 0, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 27, 'nvda stock': 7, '$meta': 0, 'meta.oq': 0, 'meta aktie': 1, 'meta platforms stock': 12, 'meta stock': 87, '$v': 0, 'v.n': 9, 'v aktie': 0, 'visa stock': 4, 'v stock': 6, '$ma': 0, 'ma.n': 1, 'ma aktie': 0, 'mastercard stock': 1, 'ma stock': 3, '$avgo': 0, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 0, 'avgo stock': 2}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-11.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-12.zst: {'$aapl': 0, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 23, 'aapl stock': 7, '$msft': 0, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 10, 'msft stock': 1, '$googl': 0, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 0, 'googl stock': 1, '$nvda': 0, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 12, 'nvda stock': 2, '$meta': 0, 'meta.oq': 0, 'meta aktie': 0, 'meta platforms stock': 1, 'meta stock': 12, '$v': 3, 'v.n': 2, 'v aktie': 0, 'visa stock': 0, 'v stock': 1, '$ma': 0, 'ma.n': 0, 'ma aktie': 0, 'mastercard stock': 0, 'ma stock': 1, '$avgo': 0, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 1, 'avgo stock': 1}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-08.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-07.zst: {'$aapl': 0, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 54, 'aapl stock': 12, '$msft': 0, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 22, 'msft stock': 7, '$googl': 0, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 18, 'googl stock': 7, '$nvda': 0, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 62, 'nvda stock': 6, '$meta': 0, 'meta.oq': 0, 'meta aktie': 0, 'meta platforms stock': 4, 'meta stock': 11, '$v': 2, 'v.n': 8, 'v aktie': 0, 'visa stock': 1, 'v stock': 5, '$ma': 0, 'ma.n': 1, 'ma aktie': 0, 'mastercard stock': 1, 'ma stock': 1, '$avgo': 0, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 1, 'avgo stock': 5}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-09.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-11.zst: {'$aapl': 0, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 34, 'aapl stock': 9, '$msft': 0, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 15, 'msft stock': 5, '$googl': 0, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 5, 'googl stock': 2, '$nvda': 0, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 23, 'nvda stock': 4, '$meta': 0, 'meta.oq': 0, 'meta aktie': 0, 'meta platforms stock': 11, 'meta stock': 35, '$v': 2, 'v.n': 0, 'v aktie': 0, 'visa stock': 0, 'v stock': 4, '$ma': 1, 'ma.n': 1, 'ma aktie': 0, 'mastercard stock': 2, 'ma stock': 0, '$avgo': 0, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 0, 'avgo stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-09.zst: {'$aapl': 0, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 50, 'aapl stock': 4, '$msft': 0, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 10, 'msft stock': 2, '$googl': 0, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 3, 'googl stock': 1, '$nvda': 0, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 46, 'nvda stock': 4, '$meta': 0, 'meta.oq': 0, 'meta aktie': 0, 'meta platforms stock': 9, 'meta stock': 5, '$v': 0, 'v.n': 6, 'v aktie': 0, 'visa stock': 2, 'v stock': 5, '$ma': 0, 'ma.n': 0, 'ma aktie': 0, 'mastercard stock': 0, 'ma stock': 0, '$avgo': 0, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 2, 'avgo stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-08.zst: {'$aapl': 0, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 69, 'aapl stock': 7, '$msft': 0, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 11, 'msft stock': 2, '$googl': 0, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 2, 'googl stock': 1, '$nvda': 0, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 71, 'nvda stock': 7, '$meta': 0, 'meta.oq': 0, 'meta aktie': 0, 'meta platforms stock': 5, 'meta stock': 14, '$v': 0, 'v.n': 3, 'v aktie': 0, 'visa stock': 0, 'v stock': 7, '$ma': 0, 'ma.n': 1, 'ma aktie': 0, 'mastercard stock': 0, 'ma stock': 5, '$avgo': 0, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 0, 'avgo stock': 4}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Code\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker import extract_zst_file\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keywords):\n",
    "    zst_files = [os.path.join(zst_directory, filename) \n",
    "                 for filename in os.listdir(zst_directory) \n",
    "                 if filename.endswith(\".zst\") and not filename.startswith(\".\") \n",
    "                 and \"2022\" <= filename.split(\"_\")[1][:4] <= \"2022\"]\n",
    "\n",
    "    with Pool(processes=3) as pool:\n",
    "        pool.starmap(extract_zst_file, [(file_path, output_directory, keywords) for file_path in zst_files])\n",
    "\n",
    "\n",
    "zst_directory = '/Users/philippsbresny/Documents/RedditData'\n",
    "output_directory = '/Users/philippsbresny/Library/CloudStorage/OneDrive-Persönlich/VSC/Lazarus_Project/temp_tech'\n",
    "keywords = [\"$AAPL\", \"AAPL.OQ\", \"AAPL Aktie\", \"Apple Stock\", \"AAPL Stock\",\n",
    "            \"$MSFT\", \"MSFT.OQ\", \"MSFT Aktie\", \"Microsoft Stock\", \"MSFT Stock\",\n",
    "            \"$GOOGL\", \"GOOGL.OQ\", \"GOOGL Aktie\", \"Alphabet Stock\", \"GOOGL Stock\",\n",
    "            \"$NVDA\", \"NVDA.OQ\", \"NVDA Aktie\", \"NVIDIA Stock\", \"NVDA Stock\",\n",
    "            \"$META\", \"META.OQ\", \"META Aktie\", \"Meta Platforms Stock\", \"META Stock\",\n",
    "            \"$V\", \"V.N\", \"V Aktie\", \"Visa Stock\", \"V Stock\",\n",
    "            \"$MA\", \"MA.N\", \"MA Aktie\", \"Mastercard Stock\", \"MA Stock\",\n",
    "            \"$AVGO\", \"AVGO.OQ\", \"AVGO Aktie\", \"Broadcom Stock\", \"AVGO Stock\"]\n",
    "\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keywords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENERGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-07.zst...\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-10.zst...\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-12.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-10.zst: {'$xom': 0, 'xom.n': 0, 'xom aktie': 0, 'exxon mobil stock': 5, 'xom stock': 3, '$cvx': 0, 'cvx.n': 0, 'cvx aktie': 0, 'chevron stock': 5, 'cvx stock': 1, '$cop': 0, 'cop.n': 0, 'cop aktie': 0, 'conocophillips stock': 0, 'cop stock': 4, '$slb': 0, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 1, 'slb stock': 1, '$eog': 0, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 3, '$epd': 0, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 2, '$oxy': 0, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 0, 'oxy stock': 1, '$mpc': 0, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 0, 'mpc stock': 1}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-11.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-12.zst: {'$xom': 0, 'xom.n': 0, 'xom aktie': 0, 'exxon mobil stock': 1, 'xom stock': 0, '$cvx': 0, 'cvx.n': 0, 'cvx aktie': 0, 'chevron stock': 0, 'cvx stock': 1, '$cop': 0, 'cop.n': 0, 'cop aktie': 0, 'conocophillips stock': 0, 'cop stock': 1, '$slb': 0, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 0, '$eog': 0, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 1, '$epd': 0, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 1, '$oxy': 0, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 0, 'oxy stock': 2, '$mpc': 0, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 0, 'mpc stock': 1}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-08.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-07.zst: {'$xom': 0, 'xom.n': 0, 'xom aktie': 0, 'exxon mobil stock': 3, 'xom stock': 6, '$cvx': 0, 'cvx.n': 0, 'cvx aktie': 0, 'chevron stock': 2, 'cvx stock': 5, '$cop': 0, 'cop.n': 0, 'cop aktie': 0, 'conocophillips stock': 1, 'cop stock': 3, '$slb': 0, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 3, '$eog': 0, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 5, '$epd': 0, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 2, '$oxy': 0, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 2, 'oxy stock': 5, '$mpc': 0, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 1, 'mpc stock': 2}\n",
      "Processing /Users/philippsbresny/Documents/RedditData/RS_2022-09.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-11.zst: {'$xom': 0, 'xom.n': 0, 'xom aktie': 0, 'exxon mobil stock': 3, 'xom stock': 2, '$cvx': 0, 'cvx.n': 0, 'cvx aktie': 0, 'chevron stock': 2, 'cvx stock': 1, '$cop': 0, 'cop.n': 0, 'cop aktie': 0, 'conocophillips stock': 1, 'cop stock': 3, '$slb': 0, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 2, '$eog': 0, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 4, '$epd': 0, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 3, '$oxy': 0, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 0, 'oxy stock': 4, '$mpc': 0, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 0, 'mpc stock': 3}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-09.zst: {'$xom': 0, 'xom.n': 0, 'xom aktie': 0, 'exxon mobil stock': 0, 'xom stock': 0, '$cvx': 0, 'cvx.n': 0, 'cvx aktie': 0, 'chevron stock': 1, 'cvx stock': 0, '$cop': 0, 'cop.n': 0, 'cop aktie': 0, 'conocophillips stock': 0, 'cop stock': 0, '$slb': 0, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 0, '$eog': 0, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 0, '$epd': 0, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 1, 'epd stock': 0, '$oxy': 0, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 1, 'oxy stock': 3, '$mpc': 0, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 1, 'mpc stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditData/RS_2022-08.zst: {'$xom': 0, 'xom.n': 0, 'xom aktie': 0, 'exxon mobil stock': 0, 'xom stock': 7, '$cvx': 0, 'cvx.n': 0, 'cvx aktie': 0, 'chevron stock': 1, 'cvx stock': 3, '$cop': 0, 'cop.n': 0, 'cop aktie': 0, 'conocophillips stock': 0, 'cop stock': 5, '$slb': 0, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 4, '$eog': 0, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 4, '$epd': 0, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 5, '$oxy': 0, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 2, 'oxy stock': 5, '$mpc': 0, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 0, 'mpc stock': 4}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Code\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker import extract_zst_file\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keywords):\n",
    "    zst_files = [os.path.join(zst_directory, filename) \n",
    "                 for filename in os.listdir(zst_directory) \n",
    "                 if filename.endswith(\".zst\") and not filename.startswith(\".\") \n",
    "                 and \"2022\" <= filename.split(\"_\")[1][:4] <= \"2022\"]\n",
    "\n",
    "    with Pool(processes=3) as pool:\n",
    "        pool.starmap(extract_zst_file, [(file_path, output_directory, keywords) for file_path in zst_files])\n",
    "\n",
    "\n",
    "zst_directory = '/Users/philippsbresny/Documents/RedditData'\n",
    "output_directory = '/Users/philippsbresny/Library/CloudStorage/OneDrive-Persönlich/VSC/Lazarus_Project/temp_energy'\n",
    "keywords = [\"$XOM\", \"XOM.N\", \"XOM Aktie\", \"Exxon Mobil Stock\", \"XOM Stock\",\n",
    "            \"$CVX\", \"CVX.N\", \"CVX Aktie\", \"Chevron Stock\", \"CVX Stock\",\n",
    "            \"$COP\", \"COP.N\", \"COP Aktie\", \"Conocophillips Stock\", \"COP Stock\",\n",
    "            \"$SLB\", \"SLB.N\", \"SLB Aktie\", \"Schlumberger Stock\", \"SLB Stock\",\n",
    "            \"$EOG\", \"EOG.N\", \"EOG Aktie\", \"EOG Resources Stock\", \"EOG Stock\",\n",
    "            \"$EPD\", \"EPD.N\", \"EPD Aktie\", \"Enterprise Products Stock\", \"EPD Stock\",\n",
    "            \"$OXY\", \"OXY.N\", \"OXY Aktie\", \"Occidental Petroleum Stock\", \"OXY Stock\",\n",
    "            \"$MPC\", \"MPC.N\", \"MPC Aktie\", \"Marathon Petroleum Stock\", \"MPC Stock\",]\n",
    "\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keywords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMMENTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TECHNOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-11.zst...\n",
      "Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-12.zst...\n",
      "Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-10.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-11.zst: {'$aapl': 332, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 526, 'aapl stock': 44, '$msft': 71, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 79, 'msft stock': 21, '$googl': 61, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 16, 'googl stock': 5, '$nvda': 128, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 68, 'nvda stock': 17, '$meta': 261, 'meta.oq': 0, 'meta aktie': 0, 'meta platforms stock': 0, 'meta stock': 213, '$v': 33, 'v.n': 49, 'v aktie': 0, 'visa stock': 2, 'v stock': 15, '$ma': 7, 'ma.n': 4, 'ma aktie': 0, 'mastercard stock': 0, 'ma stock': 3, '$avgo': 2, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 0, 'avgo stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-12.zst: {'$aapl': 331, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 453, 'aapl stock': 41, '$msft': 96, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 72, 'msft stock': 13, '$googl': 55, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 3, 'googl stock': 2, '$nvda': 101, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 39, 'nvda stock': 7, '$meta': 120, 'meta.oq': 0, 'meta aktie': 1, 'meta platforms stock': 0, 'meta stock': 82, '$v': 25, 'v.n': 15, 'v aktie': 0, 'visa stock': 3, 'v stock': 11, '$ma': 7, 'ma.n': 3, 'ma aktie': 0, 'mastercard stock': 2, 'ma stock': 5, '$avgo': 20, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 0, 'avgo stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-10.zst: {'$aapl': 396, 'aapl.oq': 0, 'aapl aktie': 0, 'apple stock': 483, 'aapl stock': 42, '$msft': 125, 'msft.oq': 0, 'msft aktie': 0, 'microsoft stock': 64, 'msft stock': 23, '$googl': 87, 'googl.oq': 0, 'googl aktie': 0, 'alphabet stock': 13, 'googl stock': 6, '$nvda': 90, 'nvda.oq': 0, 'nvda aktie': 0, 'nvidia stock': 62, 'nvda stock': 9, '$meta': 424, 'meta.oq': 0, 'meta aktie': 2, 'meta platforms stock': 2, 'meta stock': 329, '$v': 41, 'v.n': 15, 'v aktie': 0, 'visa stock': 2, 'v stock': 16, '$ma': 10, 'ma.n': 1, 'ma aktie': 0, 'mastercard stock': 0, 'ma stock': 2, '$avgo': 4, 'avgo.oq': 0, 'avgo aktie': 0, 'broadcom stock': 0, 'avgo stock': 0}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Code\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker2 import extract_zst_file\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keywords):\n",
    "    zst_files = [os.path.join(zst_directory, filename) \n",
    "                 for filename in os.listdir(zst_directory) \n",
    "                 if filename.endswith(\".zst\") and not filename.startswith(\".\") \n",
    "                 and \"2022\" <= filename.split(\"_\")[1][:4] <= \"2022\"\n",
    "                 and filename.startswith(\"RC_\")]\n",
    "\n",
    "    with Pool(processes=3) as pool:\n",
    "        pool.starmap(extract_zst_file, [(file_path, output_directory, keywords) for file_path in zst_files])\n",
    "\n",
    "\n",
    "zst_directory = '/Users/philippsbresny/Documents/RedditComments'\n",
    "output_directory = '/Users/philippsbresny/Library/CloudStorage/OneDrive-Persönlich/VSC/Lazarus_Project/temp_tech'\n",
    "# Ihre Schlüsselwörter hier\n",
    "keywords = [\"$AAPL\", \"AAPL.OQ\", \"AAPL Aktie\", \"Apple Stock\", \"AAPL Stock\",\n",
    "            \"$MSFT\", \"MSFT.OQ\", \"MSFT Aktie\", \"Microsoft Stock\", \"MSFT Stock\",\n",
    "            \"$GOOGL\", \"GOOGL.OQ\", \"GOOGL Aktie\", \"Alphabet Stock\", \"GOOGL Stock\",\n",
    "            \"$NVDA\", \"NVDA.OQ\", \"NVDA Aktie\", \"NVIDIA Stock\", \"NVDA Stock\",\n",
    "            \"$META\", \"META.OQ\", \"META Aktie\", \"Meta Platforms Stock\", \"META Stock\",\n",
    "            \"$V\", \"V.N\", \"V Aktie\", \"Visa Stock\", \"V Stock\",\n",
    "            \"$MA\", \"MA.N\", \"MA Aktie\", \"Mastercard Stock\", \"MA Stock\",\n",
    "            \"$AVGO\", \"AVGO.OQ\", \"AVGO Aktie\", \"Broadcom Stock\", \"AVGO Stock\"]\n",
    "\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keywords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINANCIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-11.zst...\n",
      "Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-12.zst...Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-10.zst...\n",
      "\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-11.zst: {'$jpm': 41, 'jpm.n': 1, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 3, '$bac': 13, 'bac.n': 4, 'bac aktie': 0, 'bank of america stock': 6, 'bac stock': 1, '$wfc': 3, 'wfc.n': 1, 'wfc aktie': 0, 'wells fargo stock': 4, 'wfc stock': 0, '$ms': 9, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 1, 'ms stock': 6, '$axp': 6, 'axp.n': 0, 'axp aktie': 0, 'american express stock': 0, 'axp stock': 0, '$bx': 8, 'bx.n': 0, 'bx aktie': 0, 'blackstone stock': 0, 'bx stock': 0, '$gs': 16, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 1, 'gs stock': 5, '$blk': 10, 'blk.n': 1, 'blk aktie': 0, 'blackrock stock': 3, 'blk stock': 1}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-12.zst: {'$jpm': 38, 'jpm.n': 1, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 7, '$bac': 18, 'bac.n': 6, 'bac aktie': 0, 'bank of america stock': 3, 'bac stock': 0, '$wfc': 20, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 6, 'wfc stock': 0, '$ms': 21, 'ms.n': 0, 'ms aktie': 0, 'morgan stanley stock': 0, 'ms stock': 4, '$axp': 2, 'axp.n': 0, 'axp aktie': 0, 'american express stock': 0, 'axp stock': 1, '$bx': 29, 'bx.n': 1, 'bx aktie': 0, 'blackstone stock': 3, 'bx stock': 2, '$gs': 28, 'gs.n': 1, 'gs aktie': 0, 'goldman sachs stock': 1, 'gs stock': 4, '$blk': 9, 'blk.n': 6, 'blk aktie': 0, 'blackrock stock': 6, 'blk stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-10.zst: {'$jpm': 70, 'jpm.n': 0, 'jpm aktie': 0, 'jpmorgan chase stock': 0, 'jpm stock': 2, '$bac': 27, 'bac.n': 1, 'bac aktie': 0, 'bank of america stock': 3, 'bac stock': 0, '$wfc': 8, 'wfc.n': 0, 'wfc aktie': 0, 'wells fargo stock': 1, 'wfc stock': 0, '$ms': 15, 'ms.n': 2, 'ms aktie': 0, 'morgan stanley stock': 2, 'ms stock': 6, '$axp': 12, 'axp.n': 1, 'axp aktie': 0, 'american express stock': 1, 'axp stock': 1, '$bx': 11, 'bx.n': 0, 'bx aktie': 0, 'blackstone stock': 0, 'bx stock': 0, '$gs': 16, 'gs.n': 0, 'gs aktie': 0, 'goldman sachs stock': 6, 'gs stock': 4, '$blk': 12, 'blk.n': 0, 'blk aktie': 0, 'blackrock stock': 4, 'blk stock': 0}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Code\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker2 import extract_zst_file\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keywords):\n",
    "    zst_files = [os.path.join(zst_directory, filename) \n",
    "                 for filename in os.listdir(zst_directory) \n",
    "                 if filename.endswith(\".zst\") and not filename.startswith(\".\") \n",
    "                 and \"2022\" <= filename.split(\"_\")[1][:4] <= \"2022\"\n",
    "                 and filename.startswith(\"RC_\")]\n",
    "\n",
    "    with Pool(processes=3) as pool:\n",
    "        pool.starmap(extract_zst_file, [(file_path, output_directory, keywords) for file_path in zst_files])\n",
    "\n",
    "\n",
    "zst_directory = '/Users/philippsbresny/Documents/RedditComments'\n",
    "output_directory = '/Users/philippsbresny/Library/CloudStorage/OneDrive-Persönlich/VSC/Lazarus_Project'\n",
    "# Ihre Schlüsselwörter hier\n",
    "keywords = [\"$JPM\", \"JPM.N\", \"JPM Aktie\", \"JPMorgan Chase Stock\", \"JPM Stock\", \n",
    "            \"$BAC\", \"BAC.N\", \"BAC Aktie\", \"Bank of America Stock\", \"BAC Stock\", \n",
    "            \"$WFC\", \"WFC.N\", \"WFC Aktie\", \"Wells Fargo Stock\", \"WFC Stock\", \n",
    "            \"$MS\", \"MS.N\", \"MS Aktie\", \"Morgan Stanley Stock\", \"MS Stock\", \n",
    "            \"$AXP\", \"AXP.N\", \"AXP Aktie\", \"American Express Stock\", \"AXP Stock\", \n",
    "            \"$BX\", \"BX.N\", \"BX Aktie\", \"Blackstone Stock\", \"BX Stock\",\n",
    "            \"$GS\", \"GS.N\", \"GS Aktie\", \"Goldman Sachs Stock\", \"GS Stock\",\n",
    "            \"$BLK\", \"BLK.N\", \"BLK Aktie\", \"BlackRock Stock\", \"BLK Stock\"]\n",
    "\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keywords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENERGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-10.zst...Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-12.zst...\n",
      "\n",
      "Processing /Users/philippsbresny/Documents/RedditComments/RC_2022-11.zst...\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-11.zst: {'$xom': 52, 'xom.n': 1, 'xom aktie': 0, 'exxon mobil stock': 0, 'xom stock': 3, '$cvx': 21, 'cvx.n': 2, 'cvx aktie': 0, 'chevron stock': 6, 'cvx stock': 1, '$cop': 16, 'cop.n': 3, 'cop aktie': 0, 'conocophillips stock': 0, 'cop stock': 0, '$slb': 5, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 1, '$eog': 5, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 0, '$epd': 1, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 0, '$oxy': 65, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 1, 'oxy stock': 4, '$mpc': 10, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 0, 'mpc stock': 1}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-12.zst: {'$xom': 61, 'xom.n': 0, 'xom aktie': 0, 'exxon mobil stock': 0, 'xom stock': 2, '$cvx': 21, 'cvx.n': 2, 'cvx aktie': 0, 'chevron stock': 3, 'cvx stock': 0, '$cop': 10, 'cop.n': 0, 'cop aktie': 0, 'conocophillips stock': 0, 'cop stock': 0, '$slb': 21, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 0, '$eog': 0, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 0, '$epd': 2, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 0, '$oxy': 31, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 1, 'oxy stock': 0, '$mpc': 4, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 0, 'mpc stock': 0}\n",
      "Anzahl der Zeilen, die das Schlüsselwort enthalten für Datei /Users/philippsbresny/Documents/RedditComments/RC_2022-10.zst: {'$xom': 86, 'xom.n': 6, 'xom aktie': 0, 'exxon mobil stock': 1, 'xom stock': 2, '$cvx': 17, 'cvx.n': 1, 'cvx aktie': 0, 'chevron stock': 6, 'cvx stock': 0, '$cop': 12, 'cop.n': 1, 'cop aktie': 0, 'conocophillips stock': 0, 'cop stock': 0, '$slb': 37, 'slb.n': 0, 'slb aktie': 0, 'schlumberger stock': 0, 'slb stock': 0, '$eog': 3, 'eog.n': 0, 'eog aktie': 0, 'eog resources stock': 0, 'eog stock': 0, '$epd': 5, 'epd.n': 0, 'epd aktie': 0, 'enterprise products stock': 0, 'epd stock': 0, '$oxy': 37, 'oxy.n': 0, 'oxy aktie': 0, 'occidental petroleum stock': 0, 'oxy stock': 3, '$mpc': 1, 'mpc.n': 0, 'mpc aktie': 0, 'marathon petroleum stock': 0, 'mpc stock': 1}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Code\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from worker2 import extract_zst_file\n",
    "\n",
    "def extract_zst_files(zst_directory, output_directory, keywords):\n",
    "    zst_files = [os.path.join(zst_directory, filename) \n",
    "                 for filename in os.listdir(zst_directory) \n",
    "                 if filename.endswith(\".zst\") and not filename.startswith(\".\") \n",
    "                 and \"2022\" <= filename.split(\"_\")[1][:4] <= \"2022\"\n",
    "                 and filename.startswith(\"RC_\")]\n",
    "\n",
    "    with Pool(processes=3) as pool:\n",
    "        pool.starmap(extract_zst_file, [(file_path, output_directory, keywords) for file_path in zst_files])\n",
    "\n",
    "\n",
    "zst_directory = '/Users/philippsbresny/Documents/RedditComments'\n",
    "output_directory = '/Users/philippsbresny/Library/CloudStorage/OneDrive-Persönlich/VSC/Lazarus_Project/temp_energy'\n",
    "# Ihre Schlüsselwörter hier\n",
    "keywords = [\"$XOM\", \"XOM.N\", \"XOM Aktie\", \"Exxon Mobil Stock\", \"XOM Stock\",\n",
    "            \"$CVX\", \"CVX.N\", \"CVX Aktie\", \"Chevron Stock\", \"CVX Stock\",\n",
    "            \"$COP\", \"COP.N\", \"COP Aktie\", \"Conocophillips Stock\", \"COP Stock\",\n",
    "            \"$SLB\", \"SLB.N\", \"SLB Aktie\", \"Schlumberger Stock\", \"SLB Stock\",\n",
    "            \"$EOG\", \"EOG.N\", \"EOG Aktie\", \"EOG Resources Stock\", \"EOG Stock\",\n",
    "            \"$EPD\", \"EPD.N\", \"EPD Aktie\", \"Enterprise Products Stock\", \"EPD Stock\",\n",
    "            \"$OXY\", \"OXY.N\", \"OXY Aktie\", \"Occidental Petroleum Stock\", \"OXY Stock\",\n",
    "            \"$MPC\", \"MPC.N\", \"MPC Aktie\", \"Marathon Petroleum Stock\", \"MPC Stock\",]\n",
    "\n",
    "keywords = [keyword.lower() for keyword in keywords]\n",
    "\n",
    "extract_zst_files(zst_directory, output_directory, keywords)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROOF OF CONCEPT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'$aapl is going up' --> Treffer\n",
      "'Today Googl Aktie is booming' --> Treffer\n",
      "'Today I bough some shares of $MSFT' --> Treffer\n",
      "'Today I sold all my shares of $META.' --> Treffer\n",
      "'I found V.N.H.D amazing' --> Treffer\n",
      "'We need AAPL.OQ-Earnings so bad' --> Treffer\n",
      "'some gibberish $VNU&%O' --> kein Treffer\n",
      "'The company made a ' --> kein Treffer\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def keyword_search(text, keywords):\n",
    "    for keyword in keywords:\n",
    "        pattern = r'(?:^|\\W)' + re.escape(keyword.lower()) + r'(?:$|\\W)'\n",
    "        if re.search(pattern, text.lower()):\n",
    "            return \"Treffer\"\n",
    "    return \"kein Treffer\"\n",
    "\n",
    "keywords = [\"$AAPL\", \"AAPL.OQ\", \"AAPL Aktie\", \"Apple Stock\", \"AAPL Stock\",\n",
    "            \"$MSFT\", \"MSFT.OQ\", \"MSFT Aktie\", \"Microsoft Stock\", \"MSFT Stock\",\n",
    "            \"$GOOGL\", \"GOOGL.OQ\", \"GOOGL Aktie\", \"Alphabet Stock\", \"GOOGL Stock\",\n",
    "            \"$NVDA\", \"NVDA.OQ\", \"NVDA Aktie\", \"NVIDIA Stock\", \"NVDA Stock\",\n",
    "            \"$META\", \"META.OQ\", \"META Aktie\", \"Meta Platforms Stock\", \"META Stock\",\n",
    "            \"$V\", \"V.N\", \"V Aktie\", \"Visa Stock\", \"V Stock\",\n",
    "            \"$MA\", \"MA.N\", \"MA Aktie\", \"Mastercard Stock\", \"MA Stock\",\n",
    "            \"$AVGO\", \"AVGO.OQ\", \"AVGO Aktie\", \"Broadcom Stock\", \"AVGO Stock\"]\n",
    "\n",
    "texts = [\"$aapl is going up\", \"Today Googl Aktie is booming\", \"Today I bough some shares of $MSFT\",\n",
    "         \"Today I sold all my shares of $META.\", \"I found V.N.H.D amazing\", \"We need AAPL.OQ-Earnings so bad\", \n",
    "         \"some gibberish $VNU&%O\", \"The company made a \"]\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"'{text}' --> {keyword_search(text, keywords)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-lazarus.project",
   "language": "python",
   "name": "my-lazarus.project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
